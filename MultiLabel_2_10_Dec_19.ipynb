{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MultiLabel 2 10 Dec 19.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCTmsCIf2qWl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "da836510-f585-419a-d160-cefbf94f8960"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvfoPEo65hpZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"multi_hot_data_main.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4uN1XjF5nC7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[\"len\"] = data[\"para\"].str.split().str.len()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hY27AeiQ5qcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample = data[(data['len'] >= 10) & (data['len'] <=1000)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnfiuIRU5ubw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "98adc555-4d9e-45e9-8451-e5e4c57cfb6d"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from keras.models import Model, load_model \n",
        "from keras.layers import LSTM, Bidirectional, GlobalMaxPool1D, Dropout, Conv1D,Dense, Embedding, Input, GRU, GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-FpmPUs6C2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = train_test_split(sample,test_size=0.2,random_state=123)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFqBt9_N6Gj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_train = train.iloc[:,-2]\n",
        "features_test = test.iloc[:,-2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsTJUx5L6Ihf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = train.iloc[:,1:-2].values\n",
        "y_test = test.iloc[:,1:-2].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTvojyng6LJt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "fd1f3c74-159f-4dda-b4c3-db77a9d4913f"
      },
      "source": [
        "# load in pre-trained word vectors\n",
        "print('Loading word vectors...')\n",
        "word2vec = {}\n",
        "with open(\"drive/My Drive/ content glove glove.42B.300d.txt\") as f:\n",
        "  # is just a space-separated text file in the format:\n",
        "  # word vec[0] vec[1] vec[2] ...\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    vec = np.asarray(values[1:], dtype='float32')\n",
        "    word2vec[word] = vec\n",
        "print('Found %s word vectors.' % len(word2vec))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading word vectors...\n",
            "Found 1917494 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DLwwWP46N6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_VOCAB_SIZE = 20000\n",
        "EMBEDDING_DIM = 300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yl5yzTU7C-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert the sentences (strings) into integers\n",
        "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
        "tokenizer.fit_on_texts(features_train)\n",
        "sequences_train = tokenizer.texts_to_sequences(features_train)\n",
        "sequences_test = tokenizer.texts_to_sequences(features_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XggHPx1g7Fe4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e88b102d-a943-487e-89e8-75c481073c94"
      },
      "source": [
        "# get word -> integer mapping\n",
        "word2idx = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word2idx))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 105026 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNW3AFeR7HaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_SEQUENCE_LENGTH = 250"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOtGSg4J7K2G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d522e1a4-9c7e-46ce-ee22-34a5d4f4f8a1"
      },
      "source": [
        "encoded_train = pad_sequences(sequences_train,maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', encoded_train.shape)\n",
        "encoded_test = pad_sequences(sequences_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', encoded_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (19731, 250)\n",
            "Shape of data tensor: (4933, 250)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1NIHpTG7Mrp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2c068928-ec43-4116-98ee-71aa13aba181"
      },
      "source": [
        "# prepare embedding matrix\n",
        "print('Filling pre-trained embeddings...')\n",
        "num_words = min(MAX_VOCAB_SIZE, len(word2idx) + 1)\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "for word, i in word2idx.items():\n",
        "  if i < MAX_VOCAB_SIZE:\n",
        "    embedding_vector = word2vec.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      # words not found in embedding index will be all zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "print(embedding_matrix.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filling pre-trained embeddings...\n",
            "(20000, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EV9ifzfN7QLJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "from keras.engine.topology import Layer\n",
        "from keras import initializers, regularizers, constraints\n",
        "\n",
        "\n",
        "class Attention(Layer):\n",
        "    def __init__(self, step_dim,\n",
        "                 W_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, b_constraint=None,\n",
        "                 bias=True, **kwargs):\n",
        "        self.supports_masking = True\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        " \n",
        "        self.bias = bias\n",
        "        self.step_dim = step_dim\n",
        "        self.features_dim = 0\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight((input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        self.features_dim = input_shape[-1]\n",
        "\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight((input_shape[1],),\n",
        "                                     initializer='zero',\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "        else:\n",
        "            self.b = None\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        features_dim = self.features_dim\n",
        "        step_dim = self.step_dim\n",
        "\n",
        "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
        "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
        "\n",
        "        if self.bias:\n",
        "            eij += self.b\n",
        "\n",
        "        eij = K.tanh(eij)\n",
        "\n",
        "        a = K.exp(eij)\n",
        "\n",
        "        if mask is not None:\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0],  self.features_dim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlbzAh6J7eAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# note that we set trainable = False so as to keep the embeddings fixed\n",
        "embedding_layer = Embedding(\n",
        "  num_words,\n",
        "  EMBEDDING_DIM,\n",
        "  weights=[embedding_matrix],\n",
        "  input_length=MAX_SEQUENCE_LENGTH,\n",
        "  trainable=False\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ClmX-dP7l62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
        "x = embedding_layer(input_)\n",
        "x = Bidirectional(LSTM(15, return_sequences=True))(x)\n",
        "x = GlobalMaxPool1D()(x)\n",
        "output = Dense(26, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = Model(input_, output)\n",
        "model.compile(\n",
        "  loss='binary_crossentropy',\n",
        "  optimizer=Adam(lr=0.01),\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--zjZ38n7rAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Callbacks\n",
        "model_3 = ModelCheckpoint('model_bilstm_multilabel_2.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "logdir = \"logs/model_bilstm_multilabel/\"\n",
        "tensorboard_callback = TensorBoard(log_dir=logdir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVTBf4h777T4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "outputId": "1a7bbd0a-6218-4950-efe7-194a3ad48317"
      },
      "source": [
        "print('Training model...')\n",
        "r = model.fit(\n",
        "  encoded_train,\n",
        "  y_train,\n",
        "  batch_size=512,\n",
        "  epochs=15,\n",
        "  validation_data=(encoded_test,y_test),callbacks=[tensorboard_callback,model_3]\n",
        ")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model...\n",
            "Train on 19731 samples, validate on 4933 samples\n",
            "Epoch 1/15\n",
            "19731/19731 [==============================] - 43s 2ms/step - loss: 0.1227 - acc: 0.9519 - val_loss: 0.1299 - val_acc: 0.9487\n",
            "Epoch 2/15\n",
            "19731/19731 [==============================] - 44s 2ms/step - loss: 0.1198 - acc: 0.9529 - val_loss: 0.1284 - val_acc: 0.9492\n",
            "Epoch 3/15\n",
            "19731/19731 [==============================] - 43s 2ms/step - loss: 0.1174 - acc: 0.9539 - val_loss: 0.1269 - val_acc: 0.9501\n",
            "Epoch 4/15\n",
            "19731/19731 [==============================] - 43s 2ms/step - loss: 0.1152 - acc: 0.9546 - val_loss: 0.1255 - val_acc: 0.9505\n",
            "Epoch 5/15\n",
            "19731/19731 [==============================] - 43s 2ms/step - loss: 0.1135 - acc: 0.9549 - val_loss: 0.1250 - val_acc: 0.9506\n",
            "Epoch 6/15\n",
            "19731/19731 [==============================] - 43s 2ms/step - loss: 0.1118 - acc: 0.9557 - val_loss: 0.1248 - val_acc: 0.9509\n",
            "Epoch 7/15\n",
            "19731/19731 [==============================] - 43s 2ms/step - loss: 0.1104 - acc: 0.9560 - val_loss: 0.1243 - val_acc: 0.9507\n",
            "Epoch 8/15\n",
            "19731/19731 [==============================] - 43s 2ms/step - loss: 0.1087 - acc: 0.9567 - val_loss: 0.1237 - val_acc: 0.9510\n",
            "Epoch 9/15\n",
            "19731/19731 [==============================] - 42s 2ms/step - loss: 0.1075 - acc: 0.9573 - val_loss: 0.1237 - val_acc: 0.9510\n",
            "Epoch 10/15\n",
            "19731/19731 [==============================] - 43s 2ms/step - loss: 0.1061 - acc: 0.9579 - val_loss: 0.1234 - val_acc: 0.9508\n",
            "Epoch 11/15\n",
            "19731/19731 [==============================] - 43s 2ms/step - loss: 0.1051 - acc: 0.9585 - val_loss: 0.1229 - val_acc: 0.9513\n",
            "Epoch 12/15\n",
            "19731/19731 [==============================] - 43s 2ms/step - loss: 0.1042 - acc: 0.9586 - val_loss: 0.1226 - val_acc: 0.9516\n",
            "Epoch 13/15\n",
            "19731/19731 [==============================] - 43s 2ms/step - loss: 0.1029 - acc: 0.9591 - val_loss: 0.1232 - val_acc: 0.9514\n",
            "Epoch 14/15\n",
            "19731/19731 [==============================] - 44s 2ms/step - loss: 0.1016 - acc: 0.9596 - val_loss: 0.1229 - val_acc: 0.9514\n",
            "Epoch 15/15\n",
            "19731/19731 [==============================] - 43s 2ms/step - loss: 0.1013 - acc: 0.9597 - val_loss: 0.1248 - val_acc: 0.9505\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yznArWE77yf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_4 = model.predict(encoded_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgkH88Kx94Ms",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "outputId": "4c9774ea-8ec5-4f2c-e494-a14f0cdb2fd3"
      },
      "source": [
        "for thresh in np.arange(0.3, 0.601, 0.01):\n",
        "    thresh = np.round(thresh, 2)\n",
        "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(y_test, (predictions_4>thresh).astype(int),average=\"micro\")))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score at threshold 0.3 is 0.6240872359069224\n",
            "F1 score at threshold 0.31 is 0.627346374234341\n",
            "F1 score at threshold 0.32 is 0.6286886065819747\n",
            "F1 score at threshold 0.33 is 0.629284120867978\n",
            "F1 score at threshold 0.34 is 0.6307731826354996\n",
            "F1 score at threshold 0.35 is 0.6301755116920994\n",
            "F1 score at threshold 0.36 is 0.6313903236007167\n",
            "F1 score at threshold 0.37 is 0.6300170794192999\n",
            "F1 score at threshold 0.38 is 0.6294514995947041\n",
            "F1 score at threshold 0.39 is 0.6297105406881486\n",
            "F1 score at threshold 0.4 is 0.6292432521940718\n",
            "F1 score at threshold 0.41 is 0.6283131521678477\n",
            "F1 score at threshold 0.42 is 0.6273249915454853\n",
            "F1 score at threshold 0.43 is 0.625405682400501\n",
            "F1 score at threshold 0.44 is 0.6242016226480235\n",
            "F1 score at threshold 0.45 is 0.6223902297179413\n",
            "F1 score at threshold 0.46 is 0.619961274423517\n",
            "F1 score at threshold 0.47 is 0.6174902239601848\n",
            "F1 score at threshold 0.48 is 0.6161573880284638\n",
            "F1 score at threshold 0.49 is 0.6156074597139236\n",
            "F1 score at threshold 0.5 is 0.613032886723508\n",
            "F1 score at threshold 0.51 is 0.6102069643186144\n",
            "F1 score at threshold 0.52 is 0.6069657907783838\n",
            "F1 score at threshold 0.53 is 0.6049475262368815\n",
            "F1 score at threshold 0.54 is 0.6025431197280624\n",
            "F1 score at threshold 0.55 is 0.5999365280863218\n",
            "F1 score at threshold 0.56 is 0.5961993729605221\n",
            "F1 score at threshold 0.57 is 0.5943402307741893\n",
            "F1 score at threshold 0.58 is 0.5912546293288286\n",
            "F1 score at threshold 0.59 is 0.5885123642548737\n",
            "F1 score at threshold 0.6 is 0.5853851217906518\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY3dWoE6DgjO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "outputId": "27576fcb-79fd-4100-80e1-eb4054ee142f"
      },
      "source": [
        "for thresh in np.arange(0.3, 0.601, 0.01):\n",
        "    thresh = np.round(thresh, 2)\n",
        "    print(\"Precision score at threshold {0} is {1}\".format(thresh, metrics.precision_score(y_test, (predictions_4>thresh).astype(int),average=\"micro\")))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision score at threshold 0.3 is 0.5825683904389712\n",
            "Precision score at threshold 0.31 is 0.5931807566557683\n",
            "Precision score at threshold 0.32 is 0.6011477761836442\n",
            "Precision score at threshold 0.33 is 0.609327442317133\n",
            "Precision score at threshold 0.34 is 0.6184767277856136\n",
            "Precision score at threshold 0.35 is 0.6261643552059615\n",
            "Precision score at threshold 0.36 is 0.634870164281929\n",
            "Precision score at threshold 0.37 is 0.6417309992388822\n",
            "Precision score at threshold 0.38 is 0.6495650234218158\n",
            "Precision score at threshold 0.39 is 0.6572796716451944\n",
            "Precision score at threshold 0.4 is 0.6644905572394497\n",
            "Precision score at threshold 0.41 is 0.6716774039608685\n",
            "Precision score at threshold 0.42 is 0.6784103376813361\n",
            "Precision score at threshold 0.43 is 0.6844466600199401\n",
            "Precision score at threshold 0.44 is 0.6918367346938775\n",
            "Precision score at threshold 0.45 is 0.6989289446185998\n",
            "Precision score at threshold 0.46 is 0.7040245202558635\n",
            "Precision score at threshold 0.47 is 0.7100422400872053\n",
            "Precision score at threshold 0.48 is 0.7171492204899778\n",
            "Precision score at threshold 0.49 is 0.7254623044096729\n",
            "Precision score at threshold 0.5 is 0.7314343845371313\n",
            "Precision score at threshold 0.51 is 0.7366548042704626\n",
            "Precision score at threshold 0.52 is 0.7423071092921024\n",
            "Precision score at threshold 0.53 is 0.7484928118720049\n",
            "Precision score at threshold 0.54 is 0.7540570348195998\n",
            "Precision score at threshold 0.55 is 0.7602960102960103\n",
            "Precision score at threshold 0.56 is 0.765024630541872\n",
            "Precision score at threshold 0.57 is 0.7716772681620355\n",
            "Precision score at threshold 0.58 is 0.777511961722488\n",
            "Precision score at threshold 0.59 is 0.7826692187228119\n",
            "Precision score at threshold 0.6 is 0.7867634047071315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cj2NrRTyDkf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}